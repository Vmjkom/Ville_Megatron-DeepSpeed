{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/villekom/scratch/ville/Ville_Megatron-DeepSpeed/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import MegatronBertModel,MegatronBertConfig\n",
    "from deepspeed.utils.zero_to_fp32 import get_fp32_state_dict_from_zero_checkpoint\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing zero checkpoint 'checkpoints/bert/110M/global_step1000000'\n",
      "Detected checkpoint of type zero stage 1, world_size: 8\n",
      "Parsing checkpoint created by deepspeed==0.7.3\n",
      "Reconstructed fp32 state dict with 158 params 125220354 elements\n"
     ]
    }
   ],
   "source": [
    "weights = torch.load('checkpoints/bert/110M/pytorch_model.bin',map_location='cpu')\n",
    "state_dict = get_fp32_state_dict_from_zero_checkpoint('checkpoints/bert/110M')\n",
    "model_states = torch.load('checkpoints/bert/110M/global_step1000000/mp_rank_00_model_states.pt',map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'checkpoints/bert/110M/Bertbase_32gpu_bigrun_eap_nobinds_nods/iter_0195000/mp_rank_00/model_optim_rng.pt'\n",
    "model_states = torch.load(path,map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['module', 'buffer_names', 'optimizer', 'param_shapes', 'lr_scheduler', 'sparse_tensor_module_names', 'skipped_steps', 'global_steps', 'global_samples', 'dp_world_size', 'mp_world_size', 'ds_config', 'ds_version', 'args', 'checkpoint_version', 'iteration', 'tokens', 'random_rng_state', 'np_rng_state', 'torch_rng_state', 'cuda_rng_state', 'rng_tracker_states'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_states.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['language_model.embedding.word_embeddings.weight', 'language_model.embedding.position_embeddings.weight', 'language_model.embedding.tokentype_embeddings.weight', 'language_model.encoder.layers.0.attention.query_key_value.weight', 'language_model.encoder.layers.0.attention.dense.weight', 'language_model.encoder.layers.0.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.0.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.1.attention.query_key_value.weight', 'language_model.encoder.layers.1.attention.dense.weight', 'language_model.encoder.layers.1.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.1.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.2.attention.query_key_value.weight', 'language_model.encoder.layers.2.attention.dense.weight', 'language_model.encoder.layers.2.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.2.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.3.attention.query_key_value.weight', 'language_model.encoder.layers.3.attention.dense.weight', 'language_model.encoder.layers.3.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.3.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.4.attention.query_key_value.weight', 'language_model.encoder.layers.4.attention.dense.weight', 'language_model.encoder.layers.4.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.4.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.5.attention.query_key_value.weight', 'language_model.encoder.layers.5.attention.dense.weight', 'language_model.encoder.layers.5.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.5.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.6.attention.query_key_value.weight', 'language_model.encoder.layers.6.attention.dense.weight', 'language_model.encoder.layers.6.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.6.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.7.attention.query_key_value.weight', 'language_model.encoder.layers.7.attention.dense.weight', 'language_model.encoder.layers.7.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.7.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.8.attention.query_key_value.weight', 'language_model.encoder.layers.8.attention.dense.weight', 'language_model.encoder.layers.8.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.8.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.9.attention.query_key_value.weight', 'language_model.encoder.layers.9.attention.dense.weight', 'language_model.encoder.layers.9.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.9.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.10.attention.query_key_value.weight', 'language_model.encoder.layers.10.attention.dense.weight', 'language_model.encoder.layers.10.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.10.mlp.dense_4h_to_h.weight', 'language_model.encoder.layers.11.attention.query_key_value.weight', 'language_model.encoder.layers.11.attention.dense.weight', 'language_model.encoder.layers.11.mlp.dense_h_to_4h.weight', 'language_model.encoder.layers.11.mlp.dense_4h_to_h.weight', 'language_model.pooler.dense.weight', 'lm_head.dense.weight', 'binary_head.weight', 'language_model.encoder.layers.0.input_layernorm.weight', 'language_model.encoder.layers.0.input_layernorm.bias', 'language_model.encoder.layers.0.attention.query_key_value.bias', 'language_model.encoder.layers.0.attention.dense.bias', 'language_model.encoder.layers.0.post_attention_layernorm.weight', 'language_model.encoder.layers.0.post_attention_layernorm.bias', 'language_model.encoder.layers.0.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.0.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.1.input_layernorm.weight', 'language_model.encoder.layers.1.input_layernorm.bias', 'language_model.encoder.layers.1.attention.query_key_value.bias', 'language_model.encoder.layers.1.attention.dense.bias', 'language_model.encoder.layers.1.post_attention_layernorm.weight', 'language_model.encoder.layers.1.post_attention_layernorm.bias', 'language_model.encoder.layers.1.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.1.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.2.input_layernorm.weight', 'language_model.encoder.layers.2.input_layernorm.bias', 'language_model.encoder.layers.2.attention.query_key_value.bias', 'language_model.encoder.layers.2.attention.dense.bias', 'language_model.encoder.layers.2.post_attention_layernorm.weight', 'language_model.encoder.layers.2.post_attention_layernorm.bias', 'language_model.encoder.layers.2.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.2.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.3.input_layernorm.weight', 'language_model.encoder.layers.3.input_layernorm.bias', 'language_model.encoder.layers.3.attention.query_key_value.bias', 'language_model.encoder.layers.3.attention.dense.bias', 'language_model.encoder.layers.3.post_attention_layernorm.weight', 'language_model.encoder.layers.3.post_attention_layernorm.bias', 'language_model.encoder.layers.3.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.3.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.4.input_layernorm.weight', 'language_model.encoder.layers.4.input_layernorm.bias', 'language_model.encoder.layers.4.attention.query_key_value.bias', 'language_model.encoder.layers.4.attention.dense.bias', 'language_model.encoder.layers.4.post_attention_layernorm.weight', 'language_model.encoder.layers.4.post_attention_layernorm.bias', 'language_model.encoder.layers.4.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.4.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.5.input_layernorm.weight', 'language_model.encoder.layers.5.input_layernorm.bias', 'language_model.encoder.layers.5.attention.query_key_value.bias', 'language_model.encoder.layers.5.attention.dense.bias', 'language_model.encoder.layers.5.post_attention_layernorm.weight', 'language_model.encoder.layers.5.post_attention_layernorm.bias', 'language_model.encoder.layers.5.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.5.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.6.input_layernorm.weight', 'language_model.encoder.layers.6.input_layernorm.bias', 'language_model.encoder.layers.6.attention.query_key_value.bias', 'language_model.encoder.layers.6.attention.dense.bias', 'language_model.encoder.layers.6.post_attention_layernorm.weight', 'language_model.encoder.layers.6.post_attention_layernorm.bias', 'language_model.encoder.layers.6.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.6.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.7.input_layernorm.weight', 'language_model.encoder.layers.7.input_layernorm.bias', 'language_model.encoder.layers.7.attention.query_key_value.bias', 'language_model.encoder.layers.7.attention.dense.bias', 'language_model.encoder.layers.7.post_attention_layernorm.weight', 'language_model.encoder.layers.7.post_attention_layernorm.bias', 'language_model.encoder.layers.7.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.7.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.8.input_layernorm.weight', 'language_model.encoder.layers.8.input_layernorm.bias', 'language_model.encoder.layers.8.attention.query_key_value.bias', 'language_model.encoder.layers.8.attention.dense.bias', 'language_model.encoder.layers.8.post_attention_layernorm.weight', 'language_model.encoder.layers.8.post_attention_layernorm.bias', 'language_model.encoder.layers.8.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.8.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.9.input_layernorm.weight', 'language_model.encoder.layers.9.input_layernorm.bias', 'language_model.encoder.layers.9.attention.query_key_value.bias', 'language_model.encoder.layers.9.attention.dense.bias', 'language_model.encoder.layers.9.post_attention_layernorm.weight', 'language_model.encoder.layers.9.post_attention_layernorm.bias', 'language_model.encoder.layers.9.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.9.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.10.input_layernorm.weight', 'language_model.encoder.layers.10.input_layernorm.bias', 'language_model.encoder.layers.10.attention.query_key_value.bias', 'language_model.encoder.layers.10.attention.dense.bias', 'language_model.encoder.layers.10.post_attention_layernorm.weight', 'language_model.encoder.layers.10.post_attention_layernorm.bias', 'language_model.encoder.layers.10.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.10.mlp.dense_4h_to_h.bias', 'language_model.encoder.layers.11.input_layernorm.weight', 'language_model.encoder.layers.11.input_layernorm.bias', 'language_model.encoder.layers.11.attention.query_key_value.bias', 'language_model.encoder.layers.11.attention.dense.bias', 'language_model.encoder.layers.11.post_attention_layernorm.weight', 'language_model.encoder.layers.11.post_attention_layernorm.bias', 'language_model.encoder.layers.11.mlp.dense_h_to_4h.bias', 'language_model.encoder.layers.11.mlp.dense_4h_to_h.bias', 'language_model.encoder.final_layernorm.weight', 'language_model.encoder.final_layernorm.bias', 'language_model.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layernorm.weight', 'lm_head.layernorm.bias', 'binary_head.bias'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=MegatronBertConfig.from_json_file('bert/megatron_hf_model/config.json')\n",
    "model=MegatronBertModel.from_pretrained(None,config=config,state_dict=state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84ace10cd8807f08fb5f0d47cfc6c0194fed66700c4d00611c72d5df634f90bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
